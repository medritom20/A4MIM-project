\documentclass{beamer}
\usetheme{Madrid}
\usecolortheme{beaver}
\usepackage{amsmath, amsfonts, amssymb}
\usepackage{graphicx}

% Custom command for math operators
\DeclareMathOperator{\colspan}{colspan}
\DeclareMathOperator{\trace}{trace}

\title[Block CG Revisited]{Block CG Algorithms Revisited: \\ Theory and Numerical Reproduction}
\author{Siqing Cai}
\institute{Charles University}
\date{\today}

\begin{document}

% --- SLIDE 1: Title Page ---
\begin{frame}
    \titlepage
\end{frame}

% --- SLIDE 2: Table of Contents (FIXED) ---
% Replaced the manual 'Outline' with the automatic 'Table of Contents'
\begin{frame}{Table of Contents}
    \tableofcontents
\end{frame}

% --- SLIDE 3: Introduction & Motivation (Condensed) ---
\section{Introduction \& Motivation}
\begin{frame}{Introduction \& Motivation}
    \begin{block}<1->{The Problem}
        \begin{itemize}
            \item Goal: Solve $Ax = b$ for multiple $b$'s. \pause
            \item Block form: $Ax = b$, where $b, x \in \mathbb{R}^{n \times m}$ \pause
            \item $A$ is Symmetric Positive Definite (SPD)
        \end{itemize}
    \end{block}
        
    \begin{block}<2->{Core Challenge}
        \begin{itemize}
            \item Rank Deficiency: Vectors in a block become linearly dependent. \pause
            \item Leads to ill-conditioned coefficients. \pause
            \item Result: Slow convergence, loss of accuracy.
        \end{itemize}
    \end{block}

    \begin{block}<3->{Goal}
        \begin{itemize}
            \item \textbf{Goal 1 (Theory):} Clarify BCG vs. Block Lanczos relationship. \pause
            \item \textbf{Goal 2 (Practice):} Find a robust BCG variant for finite precision (i.e., handle rank deficiency).
        \end{itemize}
    \end{block}
\end{frame}

% --- Section 2 ---
\section{The "Classic" Algorithm}

% --- SLIDE 4: Classic Algorithm (RESTRUCTURED) ---
\begin{frame}{The "Classic" Algorithm: O'Leary's BCG (OL-BCG)}
    
    \begin{block}<1->{Algorithm 4 Core Recursions}
        \begin{itemize}
            \item Solution: $x_k = x_{k-1} + p_{k-1} \gamma_{k-1}$
            \item Residual: $r_k = r_{k-1} - A p_{k-1} \gamma_{k-1}$
            \item Direction: $p_k = (r_k + p_{k-1} \delta_k) \phi_k$
        \end{itemize}
    \end{block}
    
    \begin{block}<2->{Block Coefficients (HS-BCG: $\phi_k = I$)}
        \begin{itemize}
            \item Step size $\gamma_{k-1} \propto \alert{(p_{k-1}^T A p_{k-1})^{-1}}$
            \item Direction $\delta_k \propto \alert{(r_{k-1}^T r_{k-1})^{-1}}$
        \end{itemize}
    \end{block}

    \begin{alertblock}<3->{Source of Instability}
        \begin{itemize}
        \item What if $p_{k-1}$ or $r_{k-1}$ are rank-deficient?
        \item The inverses \alert{$(p_{k-1}^T A p_{k-1})^{-1}$} and \alert{$(r_{k-1}^T r_{k-1})^{-1}$}
        become singular.
        \item $\rightarrow$ Algorithm fails.
        \end{itemize}
    \end{alertblock}
\end{frame}


% --- NEW SECTION 3: Detailed Theory ---
\section{Goal 1 (Theory): BCG vs. Block Lanczos}

% --- SLIDE 5: The "Apples to Oranges" Problem ---
\begin{frame}{Goal 1: The "Apples to Oranges" Problem}
    \begin{columns}[T]
        \begin{column}{0.5\textwidth}
            \begin{block}<1->{Block Lanczos (Alg 3)}
                \begin{itemize}
                    \item Produces orthonormal blocks $V_k$.
                    \item $V_k^T V_k = I$
                    \item Defines a symmetric block-tridiagonal matrix $T_k$.
                    \item $A V_k = V_k T_k + ...$
                \end{itemize}
            \end{block}
        \end{column}
        \begin{column}{0.5\textwidth}
            \begin{block}<2->{Block CG (Alg 4)}
                \begin{itemize}
                    \item Produces residual blocks $R_k$.
                    \item $R_k$ blocks are \textit{not} orthogonal.
                    \item Defines a non-symmetric matrix $\hat{T}_k$ (Lemma 1).
                    \item $A R_k = R_k \hat{T}_k + ...$
                \end{itemize}
           \end{block}
        \end{column}
    \end{columns}
    \begin{alertblock}<3->{The Question}
        How to relate the non-orthogonal $R_k$ and $\hat{T}_k$ from BCG back to the "pure" orthogonal $V_k$ and $T_k$ from Lanczos?
    \end{alertblock}
\end{frame}

% --- SLIDE 6: The Bridge: Normalized Residuals ---
\begin{frame}{Goal 1: The Bridge (Lemma 2, Thm 1)}
    \begin{block}<1->{Step 1: Normalize the Residuals}
        \begin{itemize}
            \item We \textit{define} new, normalized blocks $\tilde{V}_k$ from the BCG residual blocks $R_k$. \pause
            \item $\tilde{v}_j = (-1)^{j-1}r_{j-1}\rho_{j-1}^{-1}$ (where $\rho_j$ are normalization factors)
        \end{itemize}
    \end{block}
    \begin{block}<2->{Step 2: Find Their Recurrence (Lemma 2)}
        \begin{itemize}
            \item These \textit{normalized} blocks $\tilde{V}_k$ \textit{do} satisfy a symmetric recurrence: \pause
            \item $A\tilde{V}_k = \tilde{V}_k \tilde{T}_k + \tilde{v}_{k+1}\tilde{\beta}_{k+1}e_k^T$ \pause
            \item This $\tilde{T}_k$ is symmetric, just like the Lanczos matrix!
        \end{itemize}
    \end{block}
    \begin{block}<3->{Step 3: Connect the Matrices (Theorem 1)}
        \begin{itemize}
            \item This new $\tilde{T}_k$ (from BCG) is not $T_k$ (from Lanczos), but they are "unitarily similar". \pause
            \item $T_k = U_k^T \tilde{T}_k U_k$ \pause
            \item This proves the deep theoretical connection.
        \end{itemize}
    \end{block}
\end{frame}

% --- SLIDE 7: The "How-To": Making the Connection Practical ---
\begin{frame}{Goal 1: The "How-To" (Theorem 2)}
    \begin{block}<1->{Making Similarity into Equality}
        \begin{itemize}
            \item \textbf{Question:} Can we force $U_k = I$ so that $\tilde{T}_k = T_k$? \pause
            \item<2-> \textbf{Answer (Theorem 2):} Yes, by carefully choosing the normalization factors $\rho_j$ at each step. \pause
            \item<3-> This involves a QR factorization: $ [\theta_j, \beta_{j+1}] = \mathrm{qr}(\sigma_j \tau_j) $
        \end{itemize}
    \end{block}
    \begin{exampleblock}<4->{The Result (Achieves Goal 1)}
        \begin{itemize}
            \item We can now compute the \textit{exact} Lanczos coefficients ($\alpha_j$, $\beta_j$) from \textit{inside} the Block CG algorithm. \pause
            \item<5-> This is the "one-to-one correspondence" the abstract mentions.
        \end{itemize}
    \end{exampleblock}
    \begin{alertblock}<6->{The Practical Pivot...}
        \begin{itemize}
        \item<6-> All of this beautiful theory (Sec 4) depends on the \textbf{full-rank assumption}. \pause
        \item<7-> ...But in finite precision, this assumption breaks down.
        \end{itemize}
    \end{alertblock}
\end{frame}


% --- NEW SECTION 4: The Practical Problem ---
\section{Goal 2 (Practice): The Core Problem} 

% --- SLIDE 8: The Problem (NEW) ---
\begin{frame}{The Core Problem: How to Handle Rank Deficiency?}
    \begin{block}<1->{What Happens in Practice?}
        \begin{itemize}
            \item The $r_k$ or $p_k$ blocks become (nearly) singular. \pause
            \item We cannot compute the coefficients (inverses fail). \pause
            \item Algorithm stagnates or fails.
        \end{itemize}
    \end{block}
        
    \begin{block}<2->{Two Competing Strategies}
        \begin{itemize}
            \item \textbf{Strategy 1: Deflation (Remove)}
                \begin{itemize}
                    \item<3-> Find and remove the linearly dependent vectors. \pause
                    \item<4-> $\rightarrow$ Block size $m$ shrinks.
                \end{itemize} \pause
            \item<5-> \textbf{Strategy 2: Regularization (Replace)}
                \begin{itemize}
                    \item<6-> Replace the "bad" basis with a "good" one (Dubrulle). \pause
                    \item<7-> $\rightarrow$ Block size $m$ is maintained.
                \end{itemize}
        \end{itemize}
    \end{block}
\end{frame}

% --- NEW SECTION 5: Solutions ---
\section{Solution 1: Regularization (Dubrulle)}

% --- SLIDE 9: Dubrulle's Idea (Refactored) ---
\begin{frame}{Dubrulle's Idea: Regularization}
    \begin{block}<1->{Concept}
        \begin{itemize}
            \item Don't deflate (remove vectors). \pause
            \item Maintain the full block size $m$. \pause
            \item Ensure blocks are always well-conditioned. \pause
            \item Mechanism: Change of basis via factorization.
        \end{itemize}
    \end{block}
        
    \begin{block}<2->{The Tool: Householder QR}
        \begin{itemize}
            \item For any (potentially singular) block $v$:
            \begin{equation*}
                [w, \sigma] = \mathrm{qr}(v, \text{"econ"})
            \end{equation*} \pause
            \item<3-> Property 1: $w$ is \textit{always} column-orthonormal. \pause
            \item<4-> Property 2: $\colspan(w) \supseteq \colspan(v)$. \pause
            \item<5-> Key: Use $w$ to continue, avoid inverting $\sigma$.
        \end{itemize}
    \end{block}
\end{frame}

% --- SLIDE 10: Solution 1A: DR-BCG (Strategy) ---
\begin{frame}{Solution 1A: Dubrulle-R (DR-BCG)}
    \begin{block}{Strategy (Algorithm 5)}
        \begin{itemize}
            \item<1-> \textbf{Regularize the \textit{Residual} block $r_k$.} \pause
            \item<2-> Derivation:
                \begin{enumerate}
                    \item<3-> QR of residual: $r_k = w_k \sigma_k$. \pause
                    \item<4-> Use $w_k$ (orthonormal) in the recursions. \pause
                    \item<5-> Smart choice of $\phi_k$.
                \end{enumerate}
        \end{itemize}
    \end{block}
\end{frame}

% --- SLIDE 11: DR-BCG (Formulas) ---
\begin{frame}{Solution 1A: DR-BCG (Formulas)}
    
    \begin{block}<1->{The "Antidote": Regularize the Residual}
        \begin{itemize}
            \item We start by factoring the (potentially bad) residual: $r_k = w_k \sigma_k$ \pause
            \item<2-> We use the \alert{orthonormal} $w_k$ to build our \textit{new} search direction $s_k$. \pause
            \item<3-> All recursions are now based on $w_k$ and $s_k$.
        \end{itemize}
    \end{block}
    
    \begin{block}<4->{Algorithm 5 Key Formula}
        \begin{align*}
            % This is the only inverse!
            \xi_{k-1} &= \alert{(s_{k-1}^T A s_{k-1})^{-1}}
        \end{align*}
    \end{block}

    \begin{exampleblock}<5->{Numerical Benefit}
        The only inverse, $\xi_{k-1}$, is now computed from $s_{k-1}$, which is built from the \alert{well-conditioned} $w_{k-1}$.
        This inverse is \textbf{stable}!
    \end{exampleblock}
\end{frame}

% --- SLIDE 12: Solution 1B: DP-BCG (Strategy) ---
\begin{frame}{Solution 1B: Dubrulle-P (DP-BCG)}
    \begin{block}{Strategy (Algorithm 6)}
        \begin{itemize}
            \item<1-> \textbf{Regularize the \textit{Direction} block $p_k$.} \pause
            \item<2-> Derivation:
                \begin{enumerate}
                    \item<3-> Use alternative formulas for $\gamma, \delta$. \pause
                    \item<4-> Regularize the new direction candidate via QR. \pause
                    \item<5-> $ [p_k, \psi_k] = \mathrm{qr}(r_k + p_{k-1} \delta_k) $
                \end{enumerate}
        \end{itemize}
    \end{block}
\end{frame}

% --- SLIDE 13: DP-BCG (Formulas) (FIXED & SPLIT 1/2) ---
\begin{frame}{Solution 1B: DP-BCG (The "Antidote")}
    
    \begin{block}<1->{The "Antidote": Regularize the Direction}
        \begin{itemize}
            \item We calculate the "classic" direction update $r_k + p_{k-1} \delta_k$. \pause
            \item<2-> Then we \textit{force it} to be orthonormal using QR:
            \begin{equation*}
                \alert{[p_k, \psi_k] = \mathrm{qr}(r_k + p_{k-1} \delta_k)}
            \end{equation*}
        \end{itemize}
    \end{block}
\end{frame}

% --- NEW SLIDE 14: DP-BCG (Formulas & Benefit) (SPLIT 2/2) ---
\begin{frame}{Solution 1B: DP-BCG (Formulas \& Benefit)}
    \begin{block}<1->{Supporting Formulas (Alg. 6)}
        \begin{align*}
            \gamma_{k-1} &= (p_{k-1}^T A p_{k-1})^{-1} p_{k-1}^T r_{k-1} \\
            \delta_k &= -(p_{k-1}^T A p_{k-1})^{-1} p_{k-1}^T A r_k
        \end{align*}
    \end{block}

    \begin{exampleblock}<2->{Numerical Benefit}
        \begin{itemize}
        \item<2-> $p_k$ is \textit{always} column-orthonormal by construction.
        \item<3-> This ensures that the inverse \alert{$(p_k^T A p_k)^{-1}$} for the \textit{next} step ($k+1$) will be well-conditioned.
        \end{itemize}
    \end{exampleblock}
\end{frame}


% --- NEW SECTION 6 ---
\section{Solution 2: Deflation (BF-BCG)}

% --- SLIDE 15: Solution 2: BF-BCG (Refactored) --- (Was 14)
\begin{frame}{Solution 2: Breakdown-Free (BF-BCG)}
     \begin{block}<1->{Strategy}
        \begin{itemize}
            \item \textbf{Deflate the Direction block.} \pause
            \item Uses same alternative formulas as DP-BCG. \pause
            \item Instead of full QR, computes orthonormal basis.
        \end{itemize}
    \end{block}
        
    \begin{alertblock}<2->{Crucial Difference: Regularize vs. Deflate}
        \begin{itemize}
            \item<3-> \textbf{DP-BCG (Regularize):}
                \begin{itemize}[<+->]
                    \item $p_k$ is always $n \times m$.
                    \item Maintains block size.
                \end{itemize}
            \item<4-> \textbf{BF-BCG (Deflate):}
                \begin{itemize}[<+->]
                    \item $p_k$ becomes $n \times m_k$, where $m_k \le m$.
                    \item Block size shrinks if rank deficient.
                \end{itemize}
        \end{itemize}
    \end{alertblock}
\end{frame}

% --- NEW SECTION 7 ---
\section{Practical Need: Preconditioning}

% --- SLIDE 16: Preconditioning (Split Slide 1/2) --- (Was 15)
\begin{frame}{Practical Need: Preconditioning}
    \begin{block}<1->{Goal}
        \begin{itemize}
            \item Accelerate convergence. \pause
            \item Use a preconditioner $M \approx A$. \pause
            \item Implicitly solve $M^{-1} A x = M^{-1} b$.
        \end{itemize}
    \end{block}

    \begin{block}<2->{Two Preconditioned Variants}
        \begin{itemize}
            \item P-DR-BCG (Algorithm 7) \pause
            \item P-DP-BCG (Algorithm 8)
        \end{itemize}
    \end{block}
\end{frame}

% --- SLIDE 17: Preconditioning Details (Split Slide 2/2) --- (Was 16)
\begin{frame}{Preconditioning: The Details}
    \begin{columns}[T]
        \begin{column}{0.5\textwidth}
            \begin{block}<1->{P-DP-BCG (Alg. 8)}
                \begin{itemize}
                    \item Simpler \pause
                    \item Only requires $M^{-1}$ action. \pause
                    \item Key step: $z_k = M^{-1}r_k$.
                \end{itemize}
            \end{block}
        \end{column}
        \begin{column}{0.5\textwidth}
            \begin{block}<2->{P-DR-BCG (Alg. 7)}
                \begin{itemize}
                    \item More complex \pause
                    \item Requires split $M=LL^T$. \pause
                    \item Needs $L^{-1}$ and $L^{-T}$ actions.
                \end{itemize}
           \end{block}
        \end{column}
    \end{columns}
\end{frame}

% --- NEW SECTION 8 ---
\section{Numerical Results}

% --- SLIDE 18: Experimental Setup (Condensed) --- (Was 17)
\begin{frame}{Experimental Setup}
    \begin{block}<1->{Software \& Matrices}
        \begin{itemize}
            \item MatLab R2023a 
            \item \texttt{bcsstk03}: $n=112$, ill-conditioned (no precon). 
            \item \texttt{s3dkt3m2}: $n=90449$, very ill-conditioned (with precon).
        \end{itemize}
    \end{block}
        
    \begin{block}<2->{Parameters}
        \begin{itemize}
            \item Right-hand sides: Random \texttt{rand(n,m)}. 
            \item Block sizes $m$: 1, 2, 4, 6, 16, 64. 
            \item Preconditioner: Incomplete Cholesky (\texttt{ichol}).
        \end{itemize}
    \end{block}
\end{frame}

% --- SLIDE 19: Results 1: HS vs. DR vs. DP --- (Was 18)
\begin{frame}{Results 1: HS vs. DR vs. DP}
    \begin{block}{Reproduction of Figures 1 \& 2}
        \centering
        \textit{[Space for Plots]}
    \end{block}
        
    \begin{block}<2->{Observations}
        \begin{itemize}
            \item HS-BCG: Performance degrades. Stagnates as $m$ increases. \pause
            \item DR-BCG \& DP-BCG: Remain stable. \pause
            \item \textbf{DR-BCG: Consistently the winner.}
                \begin{itemize}
                    \item Faster convergence.
                    \item Better max accuracy.
                \end{itemize}
        \end{itemize}
    \end{block}
\end{frame}

% --- SLIDE 20: Results 2: DP vs. BF-BCG --- (Was 19)
\begin{frame}{Results 2: DP vs. BF-BCG}
    \begin{block}{Reproduction of Figure 3}
        \centering
        \textit{[Space for Plots]}
    \end{block}
        
    \begin{block}<2->{Observations}
        \begin{itemize}
            \item BF-BCG (Deflation): Slower convergence.
            \item DP-BCG (Regularization): Clearly superior. 
            \item \textbf{Conclusion}: Regularization (Dubrulle) is practically better than Deflation (BF-BCG) in finite precision.
        \end{itemize}
    \end{block}
\end{frame}

% --- NEW SECTION 9 ---
\section{Conclusion}

% --- SLIDE 21: Conclusion (Condensed) --- (Was 20)
\begin{frame}{Conclusion}
    \begin{block}<1->{Summary of Findings}
        \begin{itemize}
            \item O'Leary/HS-BCG is numerically fragile for $m > 1$. \pause
            \item Dubrulle's regularization is an effective, stable remedy. \pause
            \item Regularization (DR, DP)  Deflation (BF) in practice. \pause
            \item \textbf{DR-BCG shows the best overall performance.}
        \end{itemize}
    \end{block}
        
    \begin{alertblock}<2->{Practical Recommendation}
        For solving block linear systems, the preconditioned DR-BCG variant (Algorithm 7) is the most robust and efficient choice.
    \end{alertblock}
\end{frame}

\end{document}